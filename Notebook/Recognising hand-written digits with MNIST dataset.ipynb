{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural Network to read the MNIST Dataset \n",
    "### Conor O'Reilly - G00338592"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* [towardsdatascience article](https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d) <br />\n",
    "* [medium article](https://medium.com/coinmonks/handwritten-digit-prediction-using-convolutional-neural-networks-in-tensorflow-with-keras-and-live-5ebddf46dc8)<br />\n",
    "* [tensorflow guide](https://www.tensorflow.org/guide/keras/save_and_serialize)<br />\n",
    "* [Keras Documentation](https://keras.io)<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow, keras and numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# import the mnist dataset from keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# matplotlib used to visualise the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Dataset and Printing Out Some Data & Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the dataset\n",
    "# x_train is the image of number, y_train is the number the image contains\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (Amount of images in the dataset, Rows of pixels, Cols of pixels)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13913fc50>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prints out the first image as it appears in the train set\n",
    "%matplotlib inline \n",
    "image_index = 0\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot out the first nine images in the train set in black & white\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping the Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# The input shape that the CNN expects is a 4D Array - batch, height, width, channels\n",
    "# The channels show whether the image is greyscaled or coloured\n",
    "# 1 is given because greyscaled images are being used (3 for coloured)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "# input: 28*28 pixels with 1 channel -> (28,28,1) tensors.\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Type float\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "# dataset has each pixel between 0-255, it is now 0-1\n",
    "# http://aishack.in/tutorials/normalized-rgb/\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# print outs\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Sequential Model and Adding Layers\n",
    "\n",
    "### Creating the Model\n",
    "* The Sequential model is a linear stack of layers\n",
    "* Layers are added via the add. method \n",
    "    \n",
    "    ```python\n",
    "    model = Sequential()```\n",
    "\n",
    "\n",
    "### 2D Convolution layer (e.g. spatial convolution over images)\n",
    "* This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs\n",
    "* in the first layer, you must specify the expected input data shape\n",
    "* This applies 28 convolution filters of size 3x3 each\n",
    "    \n",
    "    ```python\n",
    "    model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))```\n",
    "\n",
    "\n",
    "### Max pooling operation for spatial data\n",
    "* The pool size halves the input in both spatial dimension (vertical, horizontal).\n",
    "* The numbers input to the pool size are the factors by which to downsize\n",
    "\n",
    "    ```python \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))```\n",
    "\n",
    "==> (None, 26, 26, 28) -> (None, 13, 13, 28)\n",
    "\n",
    "### Flatten layer\n",
    "* Flattens the input. Does not affect the batch size.\n",
    "\n",
    "    ```python\n",
    "    model.add(Flatten())```\n",
    "\n",
    "==> (None, 13, 13, 28) -> (None, 4732)\n",
    "\n",
    "\n",
    "### Densely-Connected Layer\n",
    "* Dense(128) is a fully-connected layer with 128 hidden units. \n",
    "\n",
    "    ```python\n",
    "    model.add(Dense(128, activation=tf.nn.relu))```\n",
    "\n",
    "==> (None, 4732) * 128 -> 605824\n",
    "\n",
    "### Dropout Layer\n",
    "* Applies Dropout to the input.\n",
    "* Used to prevent overfitting the model by dropping a fraction rate (0.2) of inputs to 0\n",
    "\n",
    "    ```python\n",
    "    model.add(Dropout(0.2))```\n",
    "\n",
    "### Second Dense Layer with Softmax Activation\n",
    "\n",
    "   ```python\n",
    "    model.add(Dense(10,activation=tf.nn.softmax))```\n",
    "\n",
    "==> 10 * (128 + 1) -> 1290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring and Training the Model\n",
    "* Optimizers are one of two arguments required for the model\n",
    "```python\n",
    "optimizer='adam'```\n",
    "* Loss functions are the second of the two arguments required for the model\n",
    "```python\n",
    "loss='sparse_categorical_crossentropy'```\n",
    "\n",
    "* The metric is the function that judges the performance of the model\n",
    "```python\n",
    " metrics=['accuracy']```\n",
    "\n",
    "* Fit trains the model for a fixed number of epochs (iterations on the dataset)\n",
    "```python\n",
    "model.fit(x=x_train,y=y_train, epochs=10)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 48s 801us/step - loss: 0.2088 - accuracy: 0.9369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x138177e80>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 269us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09097131103184074, 0.9725000262260437]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the loss value & metrics values for the model in test mode.\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4732)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               605824    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 607,394\n",
      "Trainable params: 607,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"../FlaskWebApp/model/model.json\", \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "\n",
    "model.save('../FlaskWebApp/model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unexpected keyword argument passed to optimizer: learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-35fa9318678e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0moptimizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       optimizer = optimizers.deserialize(\n\u001b[0;32m--> 249\u001b[0;31m           optimizer_config, custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m       \u001b[0;31m# Recover loss functions and metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    836\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m       printable_module_name='optimizer')\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 list(custom_objects.items())))\n\u001b[1;32m    193\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m       \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lr, beta_1, beta_2, epsilon, decay, amsgrad, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m                \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                **kwargs):\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         raise TypeError('Unexpected keyword argument '\n\u001b[0;32m---> 68\u001b[0;31m                         'passed to optimizer: ' + str(k))\n\u001b[0m\u001b[1;32m     69\u001b[0m       \u001b[0;31m# checks that clipnorm >= 0 and clipvalue >= 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unexpected keyword argument passed to optimizer: learning_rate"
     ]
    }
   ],
   "source": [
    "#new_model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
